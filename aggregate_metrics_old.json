{
  "aggregate_metrics": {
    "generated_what_conciseness_score": {
      "mean": 1.2678571428571428,
      "median": 1.0,
      "std_dev": 0.4468504500113261,
      "min": 1.0,
      "max": 2.0,
      "count": 56
    },
    "generated_why_conciseness_score": {
      "mean": 1.6666666666666667,
      "median": 2.0,
      "std_dev": 0.47559486560567094,
      "min": 1.0,
      "max": 2.0,
      "count": 57
    },
    "what_rouge1_f1": {
      "mean": 0.15147982585110673,
      "median": 0.14061096136567836,
      "std_dev": 0.06945285459770653,
      "min": 0.033057851239669415,
      "max": 0.2828282828282828,
      "count": 52
    },
    "what_rouge1_precision": {
      "mean": 0.10595949763032782,
      "median": 0.096875,
      "std_dev": 0.06031926390990484,
      "min": 0.018604651162790697,
      "max": 0.2545454545454545,
      "count": 52
    },
    "what_rouge1_recall": {
      "mean": 0.35320237633375506,
      "median": 0.3333333333333333,
      "std_dev": 0.13398337076345163,
      "min": 0.12903225806451613,
      "max": 0.6666666666666666,
      "count": 52
    },
    "what_rouge2_f1": {
      "mean": 0.013589784663521566,
      "median": 0.010291005291005292,
      "std_dev": 0.016296747195801084,
      "min": 0.0,
      "max": 0.055944055944055944,
      "count": 52
    },
    "what_rouge2_precision": {
      "mean": 0.009424026965658559,
      "median": 0.006743256743256744,
      "std_dev": 0.011741645658717124,
      "min": 0.0,
      "max": 0.0392156862745098,
      "count": 52
    },
    "what_rouge2_recall": {
      "mean": 0.03291187588029239,
      "median": 0.01770050125313283,
      "std_dev": 0.04275257171192465,
      "min": 0.0,
      "max": 0.18181818181818182,
      "count": 52
    },
    "what_rougeL_f1": {
      "mean": 0.09738822372810242,
      "median": 0.0949163449163449,
      "std_dev": 0.03844751117735604,
      "min": 0.027149321266968326,
      "max": 0.19512195121951217,
      "count": 52
    },
    "what_rougeL_precision": {
      "mean": 0.0674137056591027,
      "median": 0.06142241379310345,
      "std_dev": 0.03413737556542666,
      "min": 0.013953488372093023,
      "max": 0.16,
      "count": 52
    },
    "what_rougeL_recall": {
      "mean": 0.2405678039985549,
      "median": 0.21806526806526805,
      "std_dev": 0.11401874659327084,
      "min": 0.08695652173913043,
      "max": 0.6363636363636364,
      "count": 52
    },
    "why_rouge1_f1": {
      "mean": 0.16681312185327926,
      "median": 0.15254237288135594,
      "std_dev": 0.07342827046173393,
      "min": 0.047619047619047616,
      "max": 0.3888888888888889,
      "count": 45
    },
    "why_rouge1_precision": {
      "mean": 0.13536198233995078,
      "median": 0.11864406779661017,
      "std_dev": 0.07794445240580614,
      "min": 0.026785714285714284,
      "max": 0.34146341463414637,
      "count": 45
    },
    "why_rouge1_recall": {
      "mean": 0.27493285019987734,
      "median": 0.25,
      "std_dev": 0.0968310169825071,
      "min": 0.125,
      "max": 0.5454545454545454,
      "count": 45
    },
    "why_rouge2_f1": {
      "mean": 0.01852093843816187,
      "median": 0.016129032258064516,
      "std_dev": 0.022690110763396526,
      "min": 0.0,
      "max": 0.0821917808219178,
      "count": 45
    },
    "why_rouge2_precision": {
      "mean": 0.014910711607843454,
      "median": 0.01098901098901099,
      "std_dev": 0.018610650856445615,
      "min": 0.0,
      "max": 0.06557377049180328,
      "count": 45
    },
    "why_rouge2_recall": {
      "mean": 0.030100027514340058,
      "median": 0.0196078431372549,
      "std_dev": 0.04328263125897568,
      "min": 0.0,
      "max": 0.2,
      "count": 45
    },
    "why_rougeL_f1": {
      "mean": 0.11868762974915646,
      "median": 0.10928961748633878,
      "std_dev": 0.04696697261585105,
      "min": 0.031746031746031744,
      "max": 0.25,
      "count": 45
    },
    "why_rougeL_precision": {
      "mean": 0.09472490740240512,
      "median": 0.0898876404494382,
      "std_dev": 0.048640432859750254,
      "min": 0.017857142857142856,
      "max": 0.23529411764705882,
      "count": 45
    },
    "why_rougeL_recall": {
      "mean": 0.20205292204845368,
      "median": 0.17647058823529413,
      "std_dev": 0.07789638808018612,
      "min": 0.08641975308641975,
      "max": 0.4,
      "count": 45
    },
    "what_semantic_similarity": {
      "mean": 0.44437716162285396,
      "median": 0.4330571460286785,
      "std_dev": 0.11318018484756942,
      "min": 0.2451115577367606,
      "max": 0.6668364621775027,
      "count": 52
    },
    "why_semantic_similarity": {
      "mean": 0.40736356350437264,
      "median": 0.39897806919819145,
      "std_dev": 0.12936935062027247,
      "min": 0.17779506538176232,
      "max": 0.7670886932275288,
      "count": 45
    },
    "what_summary_overlap_score": {
      "mean": 1.3653846153846154,
      "median": 1.0,
      "std_dev": 0.4862358886039942,
      "min": 1.0,
      "max": 2.0,
      "count": 52
    },
    "why_summary_overlap_score": {
      "mean": 1.2666666666666666,
      "median": 1.0,
      "std_dev": 0.4472135954999579,
      "min": 1.0,
      "max": 2.0,
      "count": 45
    },
    "summary_stats": {
      "total_items_processed": 57,
      "total_items_in_dataset": 57,
      "items_with_what_metrics": 52,
      "items_with_why_metrics": 45
    }
  },
  "metadata": {
    "generated_at": "2025-06-26T06:32:28.847606",
    "source_file": "data/experiments/tomomi_prompt_update/20250626-032019/inference_and_evaluation_metrics.json",
    "description": "Aggregate statistics computed from evaluation metrics"
  }
}